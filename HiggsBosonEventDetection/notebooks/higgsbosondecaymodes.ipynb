{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Searching for Higgs Boson Decay Modes with Deep Learning","metadata":{}},{"cell_type":"markdown","source":"### Import libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\nimport tensorflow as tf\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom keras.constraints import maxnorm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Exploration","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(r\"C:\\Users\\Snehal Thakur\\Documents\\Trainings\\TMLC\\DL\\Project3.HiggsBosonEventDetection\\training.csv\")\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe(include=\"all\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data Preprocessing ","metadata":{}},{"cell_type":"code","source":"# Check for missing values\ndf.isna().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for duplicates\ndf.duplicated().sum()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Univariate Analysis ","metadata":{}},{"cell_type":"code","source":"for col in df.columns:\n    fig = px.histogram(df,x=col,width=850,height=400)\n    fig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We should remove outliers i.e -999.0\ndf.replace(-999.0, 0,inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Univariate Analysis after removing outliers ","metadata":{}},{"cell_type":"code","source":"for col in df.columns:\n    fig = px.histogram(df,x=col,width=850,height=400)\n    fig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bivariate Analysis ","metadata":{}},{"cell_type":"code","source":"# numeric v/s categoric\nnums = ['EventId', 'DER_mass_MMC', 'DER_mass_transverse_met_lep',\n       'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt',\n       'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta', 'PRI_tau_phi',\n       'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_met', 'PRI_met_phi',\n       'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_leading_pt',\n       'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt',\n       'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_all_pt',\n       'Weight']\n\nfor col in nums:\n    plt.figure(figsize=(12,5))\n    sns.distplot(df[col][df.Label=='s'])\n    sns.distplot(df[col][df.Label=='b'])\n    plt.legend(['Label=\"s\"','Label=\"b\"'])\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the target\nplt.figure(figsize=(14,7))\n# barplot\nax1 = plt.subplot(1,2,1)\ncp = sns.countplot(x=df[\"Label\"])\nax1.set_xlabel(\" \")\nax1.set_ylabel(\" \")\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nsns.despine(top=True, right=True)\n# pieplot\nax2 = plt.subplot(1,2,2)\nplt.pie(df[\"Label\"].value_counts(),\n        labels=list(df[\"Label\"].unique()),\n        autopct='%1.2f%%',\n        pctdistance=0.8,\n        shadow=True,\n        radius=1.3,\n        textprops={'fontsize':14}\n       )\nax2.set_xlabel(\" \")\nplt.xlabel('Composition of \"Label\"', fontsize=15, labelpad=20)\nplt.subplots_adjust(wspace=0.4)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Analysis ","metadata":{}},{"cell_type":"code","source":"cor = df.corr()\nplt.figure(figsize=(18,10))\nsns.heatmap(cor,annot=True,cmap='coolwarm')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prepare the test and training data sets","metadata":{}},{"cell_type":"code","source":"X = df.drop(\"Label\",axis=1)\nX","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=np.where(df[\"Label\"] == \"s\", 0, 1)\ny","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Test Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Test Split for validation\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN Model creation\n\n# with tf.device('/device:GPU:0'):\nclassifier = Sequential()\nclassifier.add(Dense(32, activation='relu', input_dim=32, kernel_constraint=maxnorm(3)))\nclassifier.add(Dropout(0.5))\nclassifier.add(Dense(30, activation='relu', kernel_constraint=maxnorm(3)))\nclassifier.add(Dropout(0.5))\nclassifier.add(Dense(10, activation='relu', kernel_constraint=maxnorm(3)))\nclassifier.add(Dropout(0.5))\nclassifier.add(Dense(1, activation='sigmoid'))\n\nopt = tf.keras.optimizers.Adam(learning_rate=0.01)\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install pydot","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install graphviz","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from keras.utils.vis_utils import plot_model\n# plot_model(classifier, to_file='/tmp/model.png', show_shapes=True,)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model complilation \n# with tf.device('/device:GPU:0'):\ncallback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n# history = model.fit(X_train, y_train, epochs=30, batch_size=250, validation_data=(X_val, y_val), callbacks=[callback])\nhistory = classifier.fit(X_train, y_train, epochs=30, batch_size=250, validation_data=(X_val, y_val), callbacks=[callback])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  Model Evaluation ","metadata":{}},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n### Making the prediction and evaluating the model ","metadata":{}},{"cell_type":"code","source":"y_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\ny_pred","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.evaluate(X_test, y_test, verbose = 1) # Model evaluation","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [\"s\", \"b\"]\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n\ndisp.plot(cmap=plt.cm.Blues)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]}]}